import Anthropic from '@anthropic-ai/sdk'
import { NextRequest, NextResponse } from 'next/server'

// Dados est√°ticos b√°sicos agora v√™m da base de conhecimento
import {
  storeConversation,
  findSimilarConversations,
  createContextFromSimilarConversations,
} from '@/lib/supabase-vector'
// Token estimator removido - usamos prompt direto agora

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY || '',
})

// Fun√ß√£o para buscar configura√ß√µes do sistema da base de conhecimento
async function getSystemConfig(): Promise<{
  systemPrompt: string
  offTopicResponse: string
  noDataResponse: string
  curiosities: string[]
}> {
  try {
    const { searchMemories } = await import('@/lib/supabase-vector')
    const results = await searchMemories(
      'SISTEMA_PROMPTS configura√ß√µes assistente',
      1,
      0.3,
    )

    if (results.length > 0) {
      // Parse das configura√ß√µes da base de conhecimento
      return {
        systemPrompt: `Voc√™ √© o assistente do Rogerio Azevedo. 

REGRAS CR√çTICAS:
1. RESPOSTA MEGA CURTA: M√°ximo 1-2 frases
2. UM ASSUNTO S√ì: Fale de 1 hobby/projeto espec√≠fico
3. TOM CASUAL: WhatsApp style com emojis
4. TERMINE SEMPRE: Frases completas, nunca corte
5. USE S√ì OS DADOS: Nunca invente nada

FOCO: "Vender" o Rogerio destacando seus projetos e habilidades.

Use APENAS as informa√ß√µes fornecidas. Se n√£o souber, redirecione.`,

        offTopicResponse: `Desculpe, eu sou o assistente do Rogerio e sei apenas sobre fatos relacionados a ele e sua carreira. 

Quer saber uma curiosidade? ü§î`,

        noDataResponse: `N√£o tenho essa informa√ß√£o espec√≠fica sobre o Rogerio na minha base de conhecimento. 

Posso te contar sobre sua carreira profissional, projetos ou tecnologias. O que gostaria de saber? ü§î`,

        curiosities: [
          'Rogerio √© um desenvolvedor full-stack experiente com foco em React, TypeScript e Node.js!',
          'Ele tem experi√™ncia em lideran√ßa t√©cnica e comunica√ß√£o com executivos C-level!',
          'Rogerio j√° trabalhou em diversos projetos interessantes - quer saber mais sobre algum espec√≠fico?',
          'Al√©m de programador, ele tem hobbies interessantes - posso contar mais se voc√™ perguntar!',
        ],
      }
    }

    // Fallback para valores padr√£o se n√£o encontrar na base
    throw new Error('Configura√ß√µes n√£o encontradas na base')
  } catch (error) {
    console.error('‚ùå Erro ao buscar configura√ß√µes, usando fallback:', error)

    // Fallback com configura√ß√µes b√°sicas
    return {
      systemPrompt: `Voc√™ √© o assistente do Rogerio Azevedo. Use apenas as informa√ß√µes fornecidas.`,
      offTopicResponse: `Desculpe, eu sou o assistente do Rogerio e sei apenas sobre fatos relacionados a ele.`,
      noDataResponse: `N√£o tenho essa informa√ß√£o sobre o Rogerio.`,
      curiosities: ['Rogerio √© um desenvolvedor experiente!'],
    }
  }
}

// Fun√ß√£o para verificar se a pergunta √© relevante usando busca sem√¢ntica
async function isQueryRelevantToRogerio(query: string): Promise<boolean> {
  try {
    const { searchMemories } = await import('@/lib/supabase-vector')

    // Busca na base de conhecimento incluindo as categorias
    const results = await searchMemories(query, 3, 0.4)

    // Se encontrou algum resultado, considera relevante
    if (results.length > 0) {
      console.log(
        '‚úÖ Query considerada relevante - encontrados:',
        results.length,
        'resultados',
      )
      return true
    }

    // Palavras-chave b√°sicas como fallback para casos onde a busca vetorial falha
    const basicKeywords = [
      'rogerio',
      'rog√©rio',
      'azevedo',
      'voc√™',
      'vc',
      'voce',
    ]
    const lowerQuery = query.toLowerCase().trim()

    const hasBasicKeyword = basicKeywords.some(keyword =>
      lowerQuery.includes(keyword),
    )

    if (hasBasicKeyword) {
      console.log(
        '‚úÖ Query considerada relevante - cont√©m palavra-chave b√°sica',
      )
      return true
    }

    console.log('‚ùå Query n√£o considerada relevante')
    return false
  } catch (error) {
    console.error('‚ùå Erro ao verificar relev√¢ncia:', error)

    // Fallback para palavras-chave b√°sicas em caso de erro
    const basicKeywords = [
      'rogerio',
      'rog√©rio',
      'azevedo',
      'voc√™',
      'vc',
      'voce',
    ]
    const lowerQuery = query.toLowerCase().trim()

    return basicKeywords.some(keyword => lowerQuery.includes(keyword))
  }
}

// Fun√ß√£o para buscar informa√ß√µes relevantes da base vetorial
async function getRelevantKnowledge(query: string): Promise<string> {
  try {
    const { searchMemories } = await import('@/lib/supabase-vector')

    console.log('üîç Buscando conhecimento para query:', query)

    // Busca conhecimentos similares na base vetorial com threshold otimizado
    const relevantKnowledge = await searchMemories(query, 5, 0.3)

    console.log('üìö Conhecimentos encontrados:', relevantKnowledge.length)

    if (relevantKnowledge.length === 0) {
      console.log(
        '‚ö†Ô∏è Nenhum conhecimento encontrado, tentando threshold mais baixo...',
      )

      // Tenta com threshold ainda menor
      const fallbackKnowledge = await searchMemories(query, 5, 0.1)
      console.log(
        'üîÑ Fallback encontrou:',
        fallbackKnowledge.length,
        'resultados',
      )

      if (fallbackKnowledge.length === 0) {
        return ''
      }

      // Usa os resultados do fallback
      let formattedKnowledge = '\n\nCONHECIMENTO RELEVANTE (fallback):\n'
      fallbackKnowledge.forEach((knowledge, index) => {
        formattedKnowledge += `${index + 1}. ${knowledge.content}\n`
      })

      return formattedKnowledge
    }

    // Formata os conhecimentos encontrados
    let formattedKnowledge = '\n\nCONHECIMENTO RELEVANTE:\n'
    relevantKnowledge.forEach((knowledge, index) => {
      formattedKnowledge += `${index + 1}. ${knowledge.content}\n`
    })

    console.log('‚úÖ Conhecimento formatado e inclu√≠do no prompt')

    return formattedKnowledge
  } catch (error) {
    console.error('Erro ao buscar conhecimento relevante:', error)
    return ''
  }
}

export async function POST(request: NextRequest) {
  try {
    const {
      message,
      sessionId = 'default', // ID da sess√£o para mem√≥ria vetorial
    } = await request.json()

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Mensagem √© obrigat√≥ria' },
        { status: 400 },
      )
    }

    // üîí COMANDO SECRETO: Detectar se √© uma atualiza√ß√£o de conhecimento
    if (
      message.toLowerCase().startsWith('/update ') ||
      message.toLowerCase().startsWith('/atualizar ') ||
      message.toLowerCase().includes('quero atualizar meu conhecimento') ||
      message.toLowerCase().includes('preciso te contar algo')
    ) {
      console.log('üîë Comando secreto detectado - atualizando conhecimento')

      // Remove o comando da mensagem se existir
      const cleanMessage = message
        .replace(/^\/update\s+/i, '')
        .replace(/^\/atualizar\s+/i, '')
        .replace(/quero atualizar meu conhecimento:?\s*/i, '')
        .replace(/preciso te contar algo:?\s*/i, '')
        .trim()

      try {
        // Usa a mesma funcionalidade do endpoint de update-knowledge
        const { addMemory } = await import('@/lib/supabase-vector')

        // Processo similar ao endpoint de update-knowledge
        const processAndCategorizeUpdate = async (userInput: string) => {
          const categorizationPrompt = `
Voc√™ √© um assistente especializado em categorizar e processar informa√ß√µes pessoais.

Sua tarefa √© analisar a informa√ß√£o fornecida pelo usu√°rio e:
1. Identificar a categoria mais apropriada
2. Extrair as informa√ß√µes-chave
3. Reformular de forma estruturada e clara
4. Identificar se √© uma atualiza√ß√£o, adi√ß√£o ou remo√ß√£o de informa√ß√£o

CATEGORIAS DISPON√çVEIS:
- informa√ß√µes_pessoais: dados b√°sicos, localiza√ß√£o, background
- hobbies_interesses: atividades de lazer, passatempos, entretenimento
- carreira_profissional: trabalho atual, empresas, cargos, responsabilidades
- projetos: projetos pessoais, profissionais, side projects
- habilidades_tecnicas: tecnologias, linguagens, ferramentas, compet√™ncias
- experiencias: experi√™ncias passadas, aprendizados, conquistas
- familia_relacionamentos: fam√≠lia, relacionamentos pessoais
- objetivos_planos: metas futuras, planos, aspira√ß√µes
- preferencias_gostos: gostos pessoais, prefer√™ncias, opini√µes

FORMATO DE RESPOSTA (JSON):
{
  "categoria": "categoria_identificada",
  "tipo_atualizacao": "adicionar|atualizar|remover",
  "informacao_processada": "informa√ß√£o reformulada de forma clara e estruturada",
  "palavras_chave": ["palavra1", "palavra2", "palavra3"],
  "contexto_adicional": "contexto ou detalhes relevantes se houver"
}

ENTRADA DO USU√ÅRIO: "${userInput}"

Processe esta informa√ß√£o:`

          const response = await anthropic.messages.create({
            model: 'claude-3-haiku-20240307',
            max_tokens: 500,
            temperature: 0.3,
            messages: [{ role: 'user', content: categorizationPrompt }],
          })

          const result = response.content[0]
          if (result.type !== 'text') throw new Error('Erro na categoriza√ß√£o')

          return JSON.parse(result.text)
        }

        // Processar a informa√ß√£o
        const processedInfo = await processAndCategorizeUpdate(cleanMessage)

        // Formatar para armazenamento
        const formattedInfo = {
          content: `[${processedInfo.categoria.toUpperCase()}] ${processedInfo.informacao_processada}`,
          metadata: {
            categoria: processedInfo.categoria,
            tipo_atualizacao: processedInfo.tipo_atualizacao,
            palavras_chave: processedInfo.palavras_chave,
            contexto_adicional: processedInfo.contexto_adicional,
            data_atualizacao: new Date().toISOString(),
            fonte: 'chat_secreto',
          },
        }

        // Armazenar no banco vetorial
        await addMemory(
          formattedInfo.content,
          JSON.stringify(formattedInfo.metadata),
        )

        // Retorna resposta especial para atualiza√ß√£o de conhecimento
        return NextResponse.json({
          message: `‚úÖ **Conhecimento atualizado via chat!**\n\nüìÇ **Categoria:** ${processedInfo.categoria}\nüîÑ **Tipo:** ${processedInfo.tipo_atualizacao}\nüìù **Processado:** ${processedInfo.informacao_processada}\nüè∑Ô∏è **Tags:** ${processedInfo.palavras_chave.join(', ')}\n\n*Agora posso usar essa informa√ß√£o nas pr√≥ximas conversas!* üòä`,
          timestamp: new Date().toISOString(),
          isKnowledgeUpdate: true,
          processedInfo: {
            categoria: processedInfo.categoria,
            tipo: processedInfo.tipo_atualizacao,
            conteudo: processedInfo.informacao_processada,
            palavrasChave: processedInfo.palavras_chave,
          },
        })
      } catch (error) {
        console.error('Erro ao processar atualiza√ß√£o de conhecimento:', error)
        return NextResponse.json({
          message: `‚ùå Erro ao atualizar conhecimento: ${error instanceof Error ? error.message : 'Erro desconhecido'}`,
          timestamp: new Date().toISOString(),
        })
      }
    }

    // VALIDA√á√ÉO: Verifica se a pergunta √© relevante para o Rogerio usando busca sem√¢ntica
    const isRelevant = await isQueryRelevantToRogerio(message)
    if (!isRelevant) {
      // Busca configura√ß√µes e seleciona uma curiosidade aleat√≥ria
      const config = await getSystemConfig()
      const randomCuriosity =
        config.curiosities[
          Math.floor(Math.random() * config.curiosities.length)
        ]

      return NextResponse.json({
        message: `${config.offTopicResponse}\n\n${randomCuriosity}`,
        timestamp: new Date().toISOString(),
        isOffTopic: true,
      })
    }

    // Busca conversas similares na mem√≥ria vetorial
    const similarConversations = await findSimilarConversations(
      sessionId,
      message,
    )

    console.log('üîç DEBUG - Conversas similares:', {
      sessionId,
      message,
      similarConversationsCount: similarConversations.length,
      conversations: similarConversations.map(c => ({
        userMessage: c.userMessage,
        assistantResponse: c.assistantResponse.substring(0, 100) + '...',
      })),
    })

    // Cria contexto baseado em conversas similares
    const vectorContext =
      createContextFromSimilarConversations(similarConversations)

    console.log(
      'üß† DEBUG - Contexto vetorial:',
      vectorContext.substring(0, 200) + '...',
    )

    // Busca informa√ß√µes relevantes da base vetorial
    const relevantKnowledge = await getRelevantKnowledge(message)

    // Log para verificar os dados inclu√≠dos no prompt
    console.log(
      'üîç Dados inclu√≠dos no prompt:',
      relevantKnowledge.length > 0
        ? `${relevantKnowledge.substring(0, 200)}...`
        : 'Nenhum conhecimento encontrado',
    )

    // MESMA ESTRAT√âGIA DO TESTE: dar espa√ßo suficiente para completar naturalmente
    const targetTokens = 100 // Tokens que queremos
    const maxTokens = 200 // Espa√ßo generoso para evitar truncamento

    // Busca configura√ß√µes do sistema
    const config = await getSystemConfig()

    // Cria o prompt do sistema simplificado
    const systemPrompt = `‚ö†Ô∏è ATEN√á√ÉO: ZERO INVEN√á√ÉO PERMITIDA ‚ö†Ô∏è

REGRAS ABSOLUTAS:
1. SOMENTE use informa√ß√µes que est√£o literalmente escritas abaixo
2. Se os dados n√£o mencionam algo espec√≠fico, diga "N√£o tenho essa informa√ß√£o"  
3. PROIBIDO inventar: hobbies, atividades, caracter√≠sticas pessoais
4. M√°ximo ${targetTokens} tokens - seja direto e conciso
5. SEMPRE termine frases adequadamente

DADOS REAIS SOBRE ROGERIO (USE APENAS ISTO):

${config.systemPrompt}${vectorContext}

INFORMA√á√ïES SOBRE ROGERIO AZEVEDO:${relevantKnowledge}`

    console.log(
      'üéØ Prompt final com controle de tamanho:',
      systemPrompt.substring(0, 300) + '...',
    )

    // Adiciona instru√ß√£o de concis√£o √† pergunta do usu√°rio
    const enhancedMessage = `${message}\n\nresponda de forma sucinta com um par√°grafo apenas.`

    console.log('üéØ Mensagem com instru√ß√£o de concis√£o:', enhancedMessage)

    const response = await anthropic.messages.create({
      model: 'claude-3-haiku-20240307',
      max_tokens: maxTokens,
      temperature: 0.5, // MENOS CRIATIVO PARA EVITAR INVEN√á√ïES
      system: systemPrompt,
      messages: [
        {
          role: 'user',
          content: enhancedMessage,
        },
      ],
    })

    const assistantMessage = response.content[0]

    if (assistantMessage.type !== 'text') {
      throw new Error('Resposta inv√°lida da API')
    }

    // Implementa√ß√£o EXATA do padr√£o que funciona no teste (LOOP m√∫ltiplas continua√ß√µes)
    let finalResponse = assistantMessage.text
    let wasTruncated = false
    let continuationCount = 0
    let currentResponse = response
    const maxContinuations = 1 // EXATAMENTE igual ao teste

    // Loop para continuar at√© que pare naturalmente ou atinja limite de continua√ß√µes
    while (
      currentResponse.stop_reason === 'max_tokens' &&
      continuationCount < maxContinuations
    ) {
      console.log(
        `‚ö†Ô∏è Resposta truncada (tentativa ${continuationCount + 1}), continuando gera√ß√£o...`,
      )
      wasTruncated = true
      continuationCount++

      try {
        // Continua√ß√£o mais inteligente baseada no f√≥rum OpenAI
        const currentTokens = Math.ceil(finalResponse.length / 3.5)
        const remainingTokens = Math.max(targetTokens - currentTokens, 30)

        console.log(
          `üìä Tokens atuais: ${currentTokens}, Restantes: ${remainingTokens}`,
        )

        const continuation = await anthropic.messages.create({
          model: 'claude-3-haiku-20240307',
          max_tokens: Math.min(remainingTokens + 20, 100), // Espa√ßo para completar a ideia
          temperature: 0.5, // MENOS CRIATIVO PARA EVITAR INVEN√á√ïES
          system: `Complete a resposta de forma NATURAL usando NO M√ÅXIMO ${remainingTokens} tokens restantes. 

N√ÉO repita informa√ß√µes. Continue exatamente de onde parou e TERMINE a resposta adequadamente.`,
          messages: [
            {
              role: 'user',
              content: `Pergunta original: ${message}`,
            },
            {
              role: 'assistant',
              content: finalResponse,
            },
            {
              role: 'user',
              content: `Complete a resposta em ${remainingTokens} tokens. Finalize adequadamente.`,
            },
          ],
        })

        const continuationMessage = continuation.content[0]
        if (continuationMessage.type === 'text') {
          // Remove espa√ßos duplos e conecta naturalmente (EXATO como no teste)
          finalResponse = finalResponse.trimEnd() + continuationMessage.text
          currentResponse = continuation
          console.log(`‚úÖ Continua√ß√£o ${continuationCount} bem-sucedida`)
        } else {
          break
        }
      } catch (error) {
        console.error('‚ùå Erro na continua√ß√£o:', error)
        finalResponse = finalResponse + '\n\n[Erro na continua√ß√£o]'
        break
      }
    }

    // Se ainda est√° truncado ap√≥s todas as tentativas
    if (
      currentResponse.stop_reason === 'max_tokens' &&
      continuationCount >= maxContinuations
    ) {
      console.log('‚ö†Ô∏è Limite de continua√ß√µes atingido, encerrando')
      finalResponse = finalResponse + '\n\n[Resposta pode estar incompleta]'
    }

    console.log('üìù Resposta final:', finalResponse)
    console.log('üìä Stop reason:', response.stop_reason)
    console.log('üìè Tamanho da resposta:', finalResponse.length, 'caracteres')

    // Armazena a conversa na mem√≥ria vetorial para futuras refer√™ncias
    await storeConversation(sessionId, message, finalResponse)

    return NextResponse.json({
      message: finalResponse,
      timestamp: new Date().toISOString(),
      isOffTopic: false,
      metadata: {
        stopReason: response.stop_reason,
        wasTruncated,
        wasAutoContinued: wasTruncated,
      },
    })
  } catch (error) {
    console.error('Erro no chat agent:', error)

    // Busca configura√ß√µes para resposta de erro
    const config = await getSystemConfig()

    return NextResponse.json(
      {
        error: 'Erro interno do servidor',
        message: config.noDataResponse,
      },
      { status: 500 },
    )
  }
}

export async function GET() {
  return NextResponse.json({
    status: 'AI Agent est√° funcionando!',
    model: 'Claude 3 Haiku',
    timestamp: new Date().toISOString(),
  })
}
